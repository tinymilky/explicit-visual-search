# explicit-visual-search
Developing advanced VLMs that can perform explict visual search by innate ability of copying / searching visual embedding into output sequence



## Curated datasets for VLM training:
1. Sorie: 626 unique images & 2005 VQA questions; No Gemini; images and questions are filtered with bounding box size less than 10% of the image size.
2. InfoVQA: 3191 unique images & 12711 VQA questions: Geimini boxes are filtered with OCR words & images are filtered with >1:4 <4:1 width:height ratio, 
3. DocVQA: 
4. BboxDocVQA: 
5. SlideVQA:

# Visual (image) search related datasets & benchmarks
1. SalBench: https://huggingface.co/datasets/salbench-vlm/salbench
2. TreeBench: https://huggingface.co/datasets/HaochenWang/TreeBench
3. TreeVGR-RL-37K: https://huggingface.co/datasets/HaochenWang/TreeVGR-RL-37K
4. TreeVGR-SFT-35K: https://huggingface.co/datasets/HaochenWang/TreeVGR-SFT-35K
5. VStarBench: https://huggingface.co/datasets/craigwu/vstar_bench
6. VisualProbe: https://huggingface.co/datasets/Mini-o3/VisualProbe_Hard
7. Mini-o3: https://huggingface.co/datasets/Mini-o3/Mini-o3-Coldstart-Dataset
8. DeepEyes-47K: https://huggingface.co/datasets/ChenShawn/DeepEyes-Datasets-47k
9. ThinkLite-VL-70k: https://huggingface.co/datasets/russwang/ThinkLite-VL-70k
10. ThinkLite-VL-hard-11k: https://huggingface.co/datasets/russwang/ThinkLite-VL-hard-11k
11. HR-Bench: https://huggingface.co/datasets/DreamMr/HR-Bench
12. O3-Bench: https://huggingface.co/datasets/m-Just/O3-Bench
13. VisCoT_VStar_Collage: https://huggingface.co/datasets/m-Just/VisCoT_VStar_Collage
14. InfoVQA_RegionLocalization: https://huggingface.co/datasets/m-Just/InfoVQA_RegionLocalization
15. MME-RealWorld: https://huggingface.co/datasets/yifanzhang114/MME-RealWorld
16. MME-RealWorld-Lite: https://huggingface.co/datasets/yifanzhang114/MME-RealWorld-Lite
17. RealworldQA: https://huggingface.co/datasets/xai-org/RealworldQA
18. RefSpatial: https://huggingface.co/datasets/JingkunAn/RefSpatial
19. RefSpatial-Bench: https://huggingface.co/datasets/BAAI/RefSpatial-Bench
20. RefSpatial-Expand-Bench: https://huggingface.co/datasets/JingkunAn/RefSpatial-Expand-Bench

# Dense-annotated image data
1. OpenImages-1.9M: https://huggingface.co/datasets/bitmind/open-images-v7-subset-splits
2. 

# Video search related datasets & benchmarks
1. Video-R1-260K: ttps://huggingface.co/datasets/Video-R1/Video-R1-data


# General VLM training datasets backups
1. PE-videos-120K: https://huggingface.co/datasets/facebook/PE-Video
2. PLM-Video-Human: https://huggingface.co/datasets/facebook/PLM-Video-Human
3. PLM-Video-Auto: https://huggingface.co/datasets/facebook/PLM-Video-Auto



# Seed Visual Search dataset
1. VisualGenome: https://huggingface.co/datasets/BoyangZ/VisualGenome_VG_100K_1_and_2, https://homes.cs.washington.edu/~ranjay/visualgenome/api.html
2. OCR-VQA: https://huggingface.co/datasets/howard-hou/OCR-VQA
3. BBox DocVQA: https://huggingface.co/datasets/Yuwh07/BBox_DocVQA_Train
4. LVIS: https://www.lvisdataset.org/
5. SODA-D: https://shaunyuan22.github.io/SODA/
6. Mulberry-SFT-270K: https://huggingface.co/datasets/HuanjinYao/Mulberry-SFT
7. LLaVA-CoT-100k: https://huggingface.co/datasets/Xkev/LLaVA-CoT-100k

# Visual Input for Math reasoning (language based)
1. MM-Eureka-54K: https://huggingface.co/datasets/FanqingM/MM-Eureka-Dataset
2. MMK-12: https://huggingface.co/datasets/FanqingM/MMK12

